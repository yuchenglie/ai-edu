Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https：//github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 卷积核的权重矩阵

```Python
class ConvWeightsBias(WeightsBias):
    def __init__(self, output_c, input_c, filter_h, filter_w, init_method, optimizer_name, eta):
        self.KernalCount = output_c
        self.FilterCount = input_c
        self.FilterHeight = filter_h
        self.FilterWidth = filter_w
        self.init_method = init_method
        self.optimizer_name = optimizer_name
        self.eta = eta
```
- KernalCount - 卷积核数量，一个卷积权重矩阵里包含一至多个卷积核，每个卷积核对应着一个输出通道，所以KernalCount = output_c。
- FilterCount - 过滤器数量，在一个卷积核内，每个通道都对应着一个过滤器，所以FilterCount = input_c
- FilterHeight, FilterWidgh - 过滤器的高度宽度，一般同为奇数
- init_method - 在使用ReLU激活函数时，一般用MSRA/HE初始化
- optimizer_name - 优化器的名称，如Adam等
- eta - 即学习率Learning Rate，在初始化优化器时使用

## 基本方法

- Initialize - 初始化
- CreateNew - 建立一个新的权重矩阵（与之相对的是使用以前相同的数据建立权重矩阵，以便于算法比较）
- Rotate180 - 将每个filter旋转180度，为了求前向梯度
- ClearGrads - 清空上次计算的梯度值
- MeanGrads - 梯度值除以样本数量
- Update - 更新梯度，此时会调用优化器的方法


# 卷积层

```Python
class ConvLayer(CLayer):
    # define the number of input and output channel, also the filter size
    def __init__(self, 
                 input_shape,       # (InputChannelCount, H, W)
                 kernal_shape,      # (OutputChannelCount, FH, FW)
                 conv_param,        # (stride, padding)
                 activator, param):
        self.num_input_channel = input_shape[0]
        self.input_height = input_shape[1]
        self.input_width = input_shape[2]
        self.num_output_channel = kernal_shape[0]
        self.filter_height = kernal_shape[1]
        self.filter_width = kernal_shape[2]
        self.stride = conv_param[0]
        self.padding = conv_param[1]
        self.activator = activator
```

## 成员变量

- num_input_channel, input_height, input_width - 输入数据的通道数，高，宽
- num_output_channel, filter_height, filter_width - 输出数据的通道数（卷积核数），卷积核过滤器的高和宽
- stride - 卷积步长
- padding - 是否填充
- activator - 激活函数

## 成员方法

- forward - 前向计算
- backward - 反向传播
- pre_update - 预更新权重（只适用于当优化器是NAG时）
- update - 更新权重
- save_parameters - 保存训练结果
- load_parameters - 加载训练结果

# 池化层

```Python
class PoolingLayer(CLayer):
    def __init__(self,
                input_shape,    # (input_c, input_h, input_w)
                pool_shape,     # (pool_h, pool_w)
                stride, 
                pool_type):  # MAX, MEAN
        self.num_input_channel = input_shape[0]
        self.input_height = input_shape[1]
        self.input_width = input_shape[2]
        self.pool_height = pool_shape[0]
        self.pool_width = pool_shape[1]
        self.stride = stride
        self.pool_type = pool_type
        self.pool_size = self.pool_height * self.pool_width
        self.output_height = (self.input_height - self.pool_height) // self.stride + 1
        self.output_width = (self.input_width - self.pool_width) // self.stride + 1
        self.output_shape = (self.num_input_channel, self.output_height, self.output_width)
        self.output_size = self.num_input_channel * self.output_height * self.output_width
```

## 成员变量

- num_input_channel, input_height, input_width - 输入数据的通道数，高，宽
- pool_height, pool_width - 池的高和宽（一般高等于宽）
- stride - 池的步长（一般等于池高，也有个别不等的）
- pooling_type - 最大池化还是平均池化（一般用最大池化）
- pool_size - 池的面积（等于池的高x宽）
- output_height, output_width - 输出数据的高和宽（不会改变通道数）

## 成员方法

- forward - 正向计算
- backward - 反向传播
- save_parameters - 保存池化尺寸、类型等设置
- load_parameters - 加载池化尺寸、类型等设置

# 实现要领

## 性能

如果完全按照卷积的定义，其计算过程是逐点相乘，然后结果求和，再移动到下一个区域，重复以上计算过程。当图片大或者卷积核多的时候（一般情况下，大图片都需要更多的卷积核来识别特征），这种重复的逐点计算非常耗时，所以在一些深度学习框架中，使用了下面的这种做法：

<img src='../Images/17/img2col.png'/>

假设Input Features有三个通道，两个卷积核，每个卷积核中需要定义三个滤波器，最后输出最上面的两个output features. 所以上面三层就是传统的卷积计算方式。

我们来看最下面那一层，根据卷积计算的规律（卷积核尺寸和步长），事先把通道一的图片（第三层最左侧）平铺到一个大矩阵中，因为步长要小于卷积核尺寸，所以数据会有重叠，比如那个[1,2,0]的2就在下面的矩阵中出现两次（第一行第2个和第二行第1个），所以这张3x3的图片会变成一个4x4的矩阵。同理，其它两个通道也做相同变换，最后形成一个4x12的大矩阵，里面包含了三个通道的所有输入数据。

再看那个Kernal Matrix，它把2x3x2x2的6个滤波器的数据，变成了12x2的大矩阵，其中12代表一个卷积核内的滤波器值，2代表两个卷积核。

上面这两个矩阵相乘，得到最右侧的Output Features(Matrix)，它的数值和最上层的Output Features的数值完全相同，只要把Output Features Matrix按正确的形状reshape就可以了。

由于对于大型矩阵运算，函数库和GPU都做了优化，所以这种变换带来的性能提高是非常可观的，数据量越大提高的性能越明显，十倍是最低的数量级。

对于池化操作，按定义我们要这样写代码：
```Python
    z = np.zeros((batch_size, input_c, output_h, output_w)).astype(np.float32)
    for b in range(batch_size):
        for c in range(input_c):
            for i in range(output_h):
                i_start = i * pool_stride
                i_end = i_start + pool_h
                for j in range(output_w):
                    j_start = j * pool_stride
                    j_end = j_start + pool_w
                    target_array = x[b,c,i_start:i_end, j_start:j_end]
                    z[b,c,i,j] = target_array.max()
```
如果是2x2的池子，步长为2的话，我们需要每4个点计算一次，虽然比卷积快了4倍，但是还有计算max值，或者mean值，也相当于每个点都遍历一遍，性能极差。

也有类似与卷积优化的方法来计算池化层。比如有以下数据：

<img src='../Images/17/img2col_pool.png'/>

在上面的图片中，我们假设大写字母为池子中的最大元素，并且用max_pool方式。

原始数据先做img2col变换，然后做一次np.max(axis=1)的max计算，会大大增加速度，然后把结果renshape成正确的矩阵即可。做一次大矩阵的max计算，比做4次小矩阵计算要快很多。

## 没有GPU咋办

用纯Python写出来的代码，运行效率比较低。在前面学习的神经网络的代码，经过高度优化，运行一般的只有全连接层的深度学习网络速度非常的快，但是一遇到卷积，立刻呆滞。

- 如果你有GPU，而且是在Linux上，那么NumPy库还是可以跑GPU版的。
- 如果你有GPU，但是是在Windows 10上，NumPy库并不支持，只好想别的办法，比如MXNET的科学计算库。
- 如果你没有GPU，可以看一下Numba这个库，http://numba.pydata.org/，用pip install numba安装

在我们的代码示例中，有一个独立的文件jit_utility.py，里面有很多简单功能函数，如：

- jit_conv_2d
- jit_conv_4d
- max_pool_forward
- max_pool_backward

等等，都是用@nb.jit(nopython=True)装饰器，让这些函数在运行前被编译成C函数库，相当于Python调用C代码来做卷积池化等操作，会比用纯Python快十倍到几十倍。但是也有缺点：

- 对NumPy函数支持有限
- 输入参数不能是自定义类型

Numba也支持GPU，但是要用到Numba定义的一些函数库，才能调用GPU设备。使用Numba可以解燃眉之急，但是在CPU上还是比GPU慢很多，只能跑一些小的卷积模型。
