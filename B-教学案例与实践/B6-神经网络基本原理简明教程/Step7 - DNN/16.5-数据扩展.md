Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# 数据扩展 Data Augmentation

过拟合的原因之一是训练数据不够，而在现代的机器学习中，数据量却是不成问题，因为通过互联网上用户的交互行为，或者和手机App的交互行为，可以收集大量的数据用于网络训练。

但是对于一些图片类数据，不是很容易从原始渠道搞到，所以可以采用增加一些假数据的方式来满足需要，尤其是当这个任务是分类任务时，更加适合。对于拟合任务，在当前样本数据附近增加一些假的样本数据并无意义，相当于把整个样本数据变“粗”。对于概率密度计算任务，增加假样本很可能破坏原始样本的概率密度。

通过丰富的图像处理手段，我们往往可以把样本数量翻好几倍。下面我们通过手写数字识别的例子，来说明如何做简单的图片增强。

## 旋转

定义图片中心和旋转角度，进行微小的旋转。

<img src="..\Images\16\data_rotate.png">

上图中，中间的是原始图片，左右是旋转后的图片。

选择操作的代码：

```Python
def rotate(image, angle):
    height, width = image.shape
    center = (height // 2, width // 2)
    rotation = cv2.getRotationMatrix2D(center, angle, 1)
    rotated_image = cv2.warpAffine(image, rotation, (width, height))
    return rotated_image
```
在调用上面的代码时，angle=10或者-10，相当于向左或向右旋转10度。

## 缩放

<img src="..\Images\16\data_stretch.png">

- 上：水平方向放大到1.2倍
- 左：垂直方向放大到1.2倍
- 中：原始图片
- 右：垂直方向缩小到0.8倍
- 下：水平方向缩小到0.8倍

## 平移和添加噪音

<img src="..\Images\16\data_translate.png">

- 上左：原始图片
- 上右：向下平移2像素
- 下左：向右平移2像素
- 下右：添加噪音

平移操作的代码：
```Python
def translate(image, distance, direction=0):
    height, width = image.shape

    if direction == 0:
        M = np.float32([[1, 0, 0], [0, 1, distance]])
    else:
        M = np.float32([[1, 0, distance], [0, 1, 0]])
    # end if

    return cv2.warpAffine(image, M, (width, height))
```    

添加噪音的代码：
```Python
def noise(image, var=0.1):
    gaussian_noise = np.random.normal(0, var ** 0.5, image.shape)
    noise_image = image + gaussian_noise
    return np.clip(noise_image, 0, 1)
```

做完上述变换后，我们得到了额外的9000个数据，连同原始的1000个数据一起保存在.npz文件中，供后面使用。

## 其它方法

- 翻转，即左右镜像，或者上下镜像，但是对于数字来说不合适
- 剪裁，从图像中随机选择一部分，再调整为原始图像大小，对于本例也不适合
- 颜色变化，在训练集像素值的RGB颜色空间进行PCA, 得到RGB空间的3个主方向向量，3个特征值, 对每幅图像的每个像素做特征值改变的运算
- 对比度变化，再图像的HSV颜色空间，改变饱和度S和亮度V分量，保持色调H不变。对每个像素的S,V分量进行指数运算，指数因子再0.25到4之间，模拟光照变化

# 在增强数据集上训练

只需要在Level0的代码基础上，修改数据集操作部分，就可以使用增强后的数据进行训练，以下是训练结果：

<img src="..\Images\16\data_result.png">

```
epoch=199, total_iteration=17910
loss_train=0.0001, accuracy_train=1.000000
loss_valid=0.3276, accuracy_valid=0.942000
epoch=199, total_iteration=17999
loss_train=0.0001, accuracy_train=1.000000
loss_valid=0.3279, accuracy_valid=0.942000
time used: 28.778401613235474
total weights abs sum= 2010.710018228446
total weights = 26520
little weights = 2613
zero weights = 29
testing...
rate=9016 / 10000 = 0.9016
```

我们可以看到还是有些过拟合的现象方式，实际上这不是数据的问题，而是这个网络太复杂，即使用原始的MNIST数据集训练，也是会过拟合的。

但是，我们可以对比下面的数据增强之前的1000个样本的训练结果：

<img src="..\Images\16\overfit_result.png">

```
epoch=199, total_iteration=1799
loss_train=0.0015, accuracy_train=1.000000
loss_valid=0.9956, accuracy_valid=0.860000
time used: 5.082462787628174
total weights abs sum= 1722.470655813152
total weights = 26520
little weights = 2815
zero weights = 27
testing...
rate=8423 / 10000 = 0.8423
```
通过对比可以发现：

1. 过拟合线性极大程度地消减了，从损失函数的U型曲线的角度可以看出来
2. 我们使用了原始的MNIST数据集中的测试集来测试两个模型：
>> - 原始1000个样本的模型的测试结果是84.23%
>> - 增强后的10000个样本的模型的测试结果是90.16%

数据增强后的样本在真实的测试数据下，准确率比增强前的样本高了很多，说明数据增强起到了很大的作用。

### 思考和试验

1. 由于MNIST数据集是灰度数据，不能采用色彩变化，但是可以有明暗亮度的变化。尝试在1000个原始数据集上用亮度变化的方式再增加1000个样本数据，再结合上面的其它数据增强方法，得到一共11000个样本，看看训练效果如何。

### 代码位置

ch16, Level5

先运行Level5_DataAugmentationGenerator.py生成数据，然后运行Level5_DataAugmentationLearner.py训练数据。