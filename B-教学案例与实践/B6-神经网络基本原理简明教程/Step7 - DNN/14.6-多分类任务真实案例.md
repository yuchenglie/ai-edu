Copyright © Microsoft Corporation. All rights reserved.
  适用于[License](https://github.com/Microsoft/ai-edu/blob/master/LICENSE.md)版权许可

# Cifar10图像分类

我们在第12章学习了MNIST手写数字识别数据集，本章我们认识一下另外一个比较常用的数据集CIFAR-10，这个数据集中包含10类图片，每类6000张，其中5000张用于训练，1000张用于测试。所以，一共有50000张训练图片，10000张测试图片。

下面是10类数据和随机抽取的图片：

<img src='../Images/14/cifar10_data.png'/>

## 数据读取

```Python
file_1 = "..\\Data\\data_batch_1.bin"
file_2 = "..\\Data\\data_batch_2.bin"
file_3 = "..\\Data\\data_batch_3.bin"
file_4 = "..\\Data\\data_batch_4.bin"
file_5 = "..\\Data\\data_batch_5.bin"
test_file = "..\\Data\\test_batch.bin"

def LoadData():
    print("reading data...")
    dr = CifarImageReader(file_1, file_2, file_3, file_4, file_5, test_file)
    dr.ReadData()
    dr.NormalizeX()
    dr.NormalizeY(YNormalizationMethod.MultipleClassifier)
    dr.GenerateValidationSet(k=20)
    print(dr.num_validation, dr.num_example, dr.num_test, dr.num_train)
    return dr
```

每张图都是彩色的，但是只有32x32点阵，比较小，放大了反而看不清楚。为了简化问题，我们把彩色图片转成灰度的：

```Python
gray_data = np.dot([0.299,0.587,0.114], color_data.reshape(3,-1)).reshape(1,1024)
```
由于我们想沿用处理MNIST数据集的思想，所以在转换成灰度图后，又直接用reshape(1,1024)转成了一个行向量。

## 模型

一共4个隐层，都用Relu()激活函数连接，最后的输出层是10分类：

<img src='../Images/14/cifar10_net.png'/>

以下是主要参数设置：

```Python
    num_input = num_feature
    num_hidden1 = 128
    num_hidden2 = 64
    num_hidden3 = 32
    num_hidden4 = 16
    num_output = 10
    max_epoch = 50
    batch_size = 32
    learning_rate = 0.01
    eps = 0.08

    params = CParameters(
        learning_rate, max_epoch, batch_size, eps,
        LossFunctionName.CrossEntropy3, 
        InitialMethod.MSRA, 
        OptimizerName.SGD)    
```
## 运行结果

<img src='../Images/14/cifar10_result.png'/>

```
epoch=49, total_iteration=74249
loss_train=0.052677, accuracy_train=1.000000
loss_valid=0.240593, accuracy_valid=0.910800
time used: 208.8354775905609
save parameters
testing...
0.9071
```

最后的识别精度位90.71%。

根据cifar10的[官方网站](http://www.cs.toronto.edu/~kriz/cifar.html)上的说明，一般的识别错误率是18%，即精度为82%，如果做了数据扩展，则可以到达89%的精度。我们在这个例子中，用彩色图片灰度化的方式，并且只用全连接网络，就达到了90%的精度，结果已经非常好了。有资料说如果搭建卷积神经网络可以达到95%的精度。

# 代码位置

ch14, Level3
